"""
=======================================================================================
ARQUIVO: cache.py (Gerenciamento de Cache para IA)
=======================================================================================

OBJETIVO:
    Prover uma camada de cache inteligente e transparente para os Agentes de IA.
    Sua fun√ß√£o principal √© evitar que requisi√ß√µes id√™nticas (mesmo contexto de dados)
    sejam enviadas repetidamente para as LLMs (OpenAI, etc.), economizando custos
    e reduzindo drasticamente o tempo de resposta.

CAMADA:
    Services / Infraestrutura (Backend).
    Atua como um middleware entre os 'Orchestrators' e a 'LLM Factory'.

RESPONSABILIDADES:
    1. Hashing Determin√≠stico: Criar assinaturas √∫nicas para contextos de dados complexos.
    2. Persist√™ncia Vol√°til: Armazenar resultados prontos no Redis com expira√ß√£o autom√°tica (TTL).
    3. Serializa√ß√£o: Converter objetos Pydantic (AtomicSuggestion) para JSON e vice-versa.
    4. Failover Silencioso: Se o cache falhar, o sistema deve continuar funcionando (chamando a IA real).

INTEGRA√á√ïES:
    - Redis: Banco de dados em mem√≥ria para armazenamento chave-valor.
    - Agentes de IA: Consumidores do cache.
    - Pydantic Models: Estrutura de dados que √© serializada/deserializada.
"""

import hashlib
import json
import logging
from typing import List, Optional, Any, Dict
import redis.asyncio as redis

from app.core.config import settings
from app.services.ai.base.base_schema import AtomicSuggestion

logger = logging.getLogger(__name__)

class AgentCache:
    """
    Gerenciador de Cache para Agentes de IA.
    
    Implementa a estrat√©gia de "Cache-Aside" simplificada:
    O agente pergunta se tem cache; se tiver, usa; se n√£o, processa e salva.
    """
    
    # Tempo de vida (TTL) do cache em segundos.
    # Decis√£o de Neg√≥cio: 24 horas foi definido como o limite seguro onde os dados do usu√°rio
    # provavelmente mudaram o suficiente para justificar uma nova an√°lise da IA.
    TTL_SECONDS = 60 * 60 * 24 

    def __init__(self):
        # Inicializa a conex√£o com o Redis usando o pool ass√≠ncrono.
        # 'decode_responses=True' garante que recebemos strings, n√£o bytes.
        self.redis = redis.from_url(settings.REDIS_URL, decode_responses=True)

    def _generate_key(self, domain: str, agent_name: str, context: Dict[str, Any]) -> str:
        """
        Gera uma chave de cache √∫nica e determin√≠stica baseada no conte√∫do do contexto.

        POR QUE ISSO EXISTE:
        Diferente de chaves simples (ID do usu√°rio), o contexto da IA √© complexo e vari√°vel.
        Precisamos garantir que se o usu√°rio enviar os mesmos dados, mas em ordem diferente
        no JSON, o hash gerado seja ID√äNTICO.

        ENTRADA:
        - domain: "financas"
        - agent_name: "spending_detective"
        - context: {"saldo": 100, "gastos": [...]}

        RETORNO:
        - String: "ai:cache:financas:spending_detective:a1b2c3d4..."
        """
        # 1. Serializa√ß√£o Determin√≠stica
        # 'sort_keys=True' √© CRUCIAL aqui. Garante que {"a": 1, "b": 2} gere o mesmo
        # hash que {"b": 2, "a": 1}. Sem isso, o cache seria ineficiente.
        context_str = json.dumps(context, sort_keys=True, default=str)
        
        # 2. Hashing
        # Usamos MD5 por ser r√°pido e suficiente para evitar colis√£o nesse cen√°rio de cache.
        # N√£o √© usado para criptografia de seguran√ßa.
        context_hash = hashlib.md5(context_str.encode('utf-8')).hexdigest()
        
        # Formato de namespace para facilitar limpeza/debug no Redis se necess√°rio
        return f"ai:cache:{domain}:{agent_name}:{context_hash}"

    async def get(self, domain: str, agent_name: str, context: Dict[str, Any]) -> Optional[List[AtomicSuggestion]]:
        """
        Tenta recuperar uma resposta pronta do cache.

        FLUXO:
        1. Gera o hash do contexto atual.
        2. Busca no Redis.
        3. Se encontrar (HIT), reconstr√≥i os objetos Pydantic originais.
        4. Se der erro (Redis fora do ar), loga e retorna None para n√£o derrubar o sistema.

        RETORNO:
        - Lista de AtomicSuggestion se houver HIT.
        - None se houver MISS ou erro.
        """
        try:
            key = self._generate_key(domain, agent_name, context)
            cached_data = await self.redis.get(key)
            
            if not cached_data:
                return None

            logger.info(f"[{agent_name}] Cache HIT ‚ö° (Key: {key})")
            
            # Deserializa√ß√£o: JSON String -> Lista de Dicts -> Lista de Objetos Pydantic
            # Isso garante que o restante do sistema receba objetos tipados, n√£o dicion√°rios brutos.
            raw_list = json.loads(cached_data)
            return [AtomicSuggestion(**item) for item in raw_list]

        except Exception as e:
            # Estrat√©gia de Resili√™ncia:
            # Falhas no cache n√£o devem impedir o funcionamento da IA.
            # Apenas logamos o erro e for√ßamos o processamento real (Bypass).
            logger.error(f"Erro ao ler cache Redis: {e}")
            return None 

    async def set(self, domain: str, agent_name: str, context: Dict[str, Any], suggestions: List[AtomicSuggestion]):
        """
        Salva o resultado do processamento da IA no Redis para uso futuro.

        REGRAS DE NEG√ìCIO:
        - N√£o cacheia listas vazias (pode ter sido um erro tempor√°rio da IA ou falta de dados).
        - Aplica TTL para evitar dados obsoletos (stale data).
        """
        try:
            if not suggestions:
                return # Prote√ß√£o contra cache de falhas ou estados vazios

            key = self._generate_key(domain, agent_name, context)
            
            # Serializa√ß√£o: Objetos Pydantic -> Lista de Dicts -> JSON String
            # 'mode=json' garante que Enums e UUIDs sejam convertidos corretamente para strings.
            data_to_save = json.dumps([s.model_dump(mode='json') for s in suggestions])
            
            await self.redis.setex(key, self.TTL_SECONDS, data_to_save)
            logger.debug(f"[{agent_name}] Cache SAVED üíæ")

        except Exception as e:
            # Falha ao salvar n√£o √© cr√≠tica para o usu√°rio, apenas perde a otimiza√ß√£o.
            logger.error(f"Erro ao salvar no cache Redis: {e}")

# ==============================================================================
# INST√ÇNCIA SINGLETON
# ==============================================================================
# Criamos uma √∫nica inst√¢ncia para ser importada em toda a aplica√ß√£o.
# Isso permite o reaproveitamento do pool de conex√µes do Redis.
ai_cache = AgentCache()